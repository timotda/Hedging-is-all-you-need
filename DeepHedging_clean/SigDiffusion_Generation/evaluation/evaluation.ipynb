{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric Presentation and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/HK_env/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import scienceplots\n",
    "plt.style.use('science')\n",
    "\n",
    "from discriminative_metrics import discriminative_score_metrics\n",
    "from predictive_metrics import predictive_score_metrics\n",
    "from metric_utils import generate_ks_results, visualization, display_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x11a40d1d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import pandas as pd \n",
    "df = pd.read_csv('/Users/timot/Desktop/Sig_Diffusions_DH/data/AMZN.csv').set_index('Date')\n",
    "df2 = df\n",
    "df2_ret = np.log(df2 / df2.shift(1)).dropna()\n",
    "np.save('/Users/timot/Desktop/Sig_Diffusions_DH/data/amzn_returns', df2_ret.to_numpy())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1228"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape[0] - int(df2.shape[0] * 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the --name argument\n",
    "experiment_name = \"amzn_returns\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 5\n",
    "real_data = np.load(f'../data/real_paths/{experiment_name}.npy')\n",
    "generated_data = np.load(f'../data/generated_paths/{experiment_name}.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 30, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(-0.15139791287665308)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_data.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minmax scale the inputs for fair comparison\n",
    "data_min = np.min(real_data, axis=(0,1), keepdims=True)\n",
    "data_max = np.max(real_data, axis=(0,1), keepdims=True)\n",
    "\n",
    "real_data = (real_data - data_min) / (data_max - data_min)\n",
    "generated_data = (generated_data - data_min) / (data_max - data_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set\n",
    "real_data = real_data[-1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 30, 1), (20000, 30, 1))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_samples, seq_len, dim = real_data.shape\n",
    "real_data.shape, generated_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminative and Predictive Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 2000/2000 [00:10<00:00, 192.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0:  0.4571428571428572 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 2000/2000 [00:10<00:00, 195.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1:  0.4519047619047619 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 2000/2000 [00:10<00:00, 196.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 2:  0.4066666666666666 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 2000/2000 [00:10<00:00, 194.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 3:  0.38976190476190475 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 2000/2000 [00:10<00:00, 192.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 4:  0.4073809523809524 \n",
      "\n",
      "aapl_returns:\n",
      "Final Score:  0.4225714285714286 ± 0.026891652937899285\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "discriminative_score = []\n",
    "\n",
    "for i in range(iterations):\n",
    "    temp_disc, fake_acc, real_acc = discriminative_score_metrics(real_data, generated_data)\n",
    "    discriminative_score.append(temp_disc)\n",
    "    print(f'Iter {i}: ', temp_disc, '\\n')\n",
    "      \n",
    "print(f'{experiment_name}:')\n",
    "display_scores(discriminative_score)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 5000/5000 [00:13<00:00, 371.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  epoch:  0.05431245403364301 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 5000/5000 [00:13<00:00, 369.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  epoch:  0.05981762884836644 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 5000/5000 [00:13<00:00, 370.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2  epoch:  0.06689297918649391 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 5000/5000 [00:13<00:00, 369.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3  epoch:  0.04993116842582822 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 5000/5000 [00:13<00:00, 368.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4  epoch:  0.05064315940253437 \n",
      "\n",
      "stocks_paths:\n",
      "Final Score:  0.056319477979373186 ± 0.006341848688444645\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predictive_score = []\n",
    "for i in range(iterations):\n",
    "    temp_pred = predictive_score_metrics(real_data, generated_data)\n",
    "    predictive_score.append(temp_pred)\n",
    "    print(i, ' epoch: ', temp_pred, '\\n')\n",
    "      \n",
    "print(f'{experiment_name}:')\n",
    "display_scores(predictive_score)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KS Test Scores on Marginals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_marginals = (0.3, 0.5, 0.7, 0.9)\n",
    "real_dataloader = DataLoader(TensorDataset(torch.tensor(real_data)), batch_size=64, shuffle=True)\n",
    "generated_dataloader = DataLoader(TensorDataset(torch.tensor(generated_data)), batch_size=64, shuffle=True)\n",
    "infinite_real_dataloader = (elem for it in iter(lambda: real_dataloader, None) for elem in it)\n",
    "infinite_generated_dataloader = (elem for it in iter(lambda: generated_dataloader, None) for elem in it)\n",
    "ks_results = generate_ks_results(infinite_real_dataloader, infinite_generated_dataloader, pct_marginals, 1000, dims=dim)\n",
    "ks_stats = ks_results[:,:,:,0]\n",
    "ks_pvals = ks_results[:,:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KS Test:\n",
      "Marginal\tMean KS\t% Reject\n",
      "0.3\t0.32\t91.70\n",
      "0.5\t0.29\t78.90\n",
      "0.7\t0.30\t80.70\n",
      "0.9\t0.45\t99.80\n"
     ]
    }
   ],
   "source": [
    "mean_score = np.mean(ks_stats, axis=0)\n",
    "std_score = np.std(ks_stats, axis=0)\n",
    "percent_reject = np.mean(ks_pvals <= 0.05, axis=0)\n",
    "# print as a table\n",
    "mean_score_per_marginal = np.mean(mean_score, axis=0)\n",
    "std_score_per_marginal = np.mean(std_score, axis=0)\n",
    "mean_pct_reject_per_marginal = np.mean(percent_reject, axis=0)\n",
    "print('KS Test:')\n",
    "print('Marginal\\tMean KS\\t% Reject')\n",
    "for i, pct in enumerate(pct_marginals):\n",
    "    print(f'{pct}\\t{mean_score_per_marginal[i]:.2f}\\t{mean_pct_reject_per_marginal[i]*100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HK_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
